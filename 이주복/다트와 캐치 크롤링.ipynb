{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 정적크롤링\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "# 동적크롤링\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의사항: 슬랙에 공유한 랠릿과 프로그래머스 파일을 현재 폴더에 지정해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "rallit = pd.read_csv('./rallit_1.csv')  # 랠릿\n",
    "programmers = pd.read_csv('./programmers.csv')  # 프로그래머스\n",
    "\n",
    "pro_corp_name = programmers['기업명']  # 프로그래머스 기업명\n",
    "ral_corp_name = rallit['기업명']  # 랠릿 기업명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다트 크롤링\n",
    "- 크롤링할 컬럼: 기업명, 주소, 업종분류, 설립연도\n",
    "- 절차\n",
    "1. 다트 공시현황 사이트 접속\n",
    "2. 기업명 타이핑하여 공시정보 접속\n",
    "3. 내용 크롤링\n",
    "4. 타이핑 되어있는 기업명 제거\n",
    "5. concat\n",
    "6. 다음 기업명 타이핑하여 공시정보 접속\n",
    "\n",
    "위 절차를 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프로그래머스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 프레임 생성\n",
    "pro_extra_res = pd.DataFrame(columns=['기업명','주소','업종분류','설립연도','기업홈페이지URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 프로그램\n",
    "url = 'https://dart.fss.or.kr/dsae001/main.do#none'\n",
    "\n",
    "driver= webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').clear()\n",
    "\n",
    "for i in pro_corp_name:\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').send_keys(i)  # 키워드 작성\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"rightWrap\"]/div[1]/div[1]/ul/li[3]/a').click()\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"rightWrap\"]/div[1]/div[1]/ul/li[3]/a').click()\n",
    "        time.sleep(.1)\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"corpTabel\"]/tbody/tr/td[1]/span/a').click()\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # 기업명\n",
    "        corp_name = i\n",
    "        # 주소\n",
    "        address = driver.find_element(By.XPATH, '//*[@id=\"corpDetailTabel\"]/tbody/tr[9]/td').text\n",
    "        # 업종명\n",
    "        sector = driver.find_element(By.XPATH, '//*[@id=\"corpDetailTabel\"]/tbody/tr[14]/td').text\n",
    "        # 설립일\n",
    "        corp_year = driver.find_element(By.XPATH, '//*[@id=\"corpDetailTabel\"]/tbody/tr[15]/td').text\n",
    "        # 기업 홈페이지URL\n",
    "        corp_url = driver.find_element(By.XPATH, '//*[@id=\"homePage\"]').text\n",
    "\n",
    "        pro_extra_temp = pd.DataFrame([corp_name,address,sector,corp_year,corp_url], index=['기업명','주소','업종분류','설립연도','기업홈페이지URL']).T\n",
    "        pro_extra_res = pd.concat([pro_extra_res, pro_extra_temp])\n",
    "\n",
    "        # 키워드 지우기\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').clear()\n",
    "        time.sleep(.1)\n",
    "        \n",
    "    except:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').clear()\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 폴더에csv파일로 저장\n",
    "pro_extra_res.to_csv('./프로그래머스_다트_추가.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랠릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 프레임 생성\n",
    "ral_extra_res = pd.DataFrame(columns=['기업명','주소','업종분류','설립연도'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 프로그램\n",
    "url = 'https://dart.fss.or.kr/dsae001/main.do#none'\n",
    "\n",
    "driver= webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').clear()  # 키워드가 있을 수 있으므로 지우기\n",
    "\n",
    "for i in ral_corp_name:  # 기업명 하나씩 불러오기\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').send_keys(i)  # 기업명 작성\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"rightWrap\"]/div[1]/div[1]/ul/li[3]/a').click()\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"rightWrap\"]/div[1]/div[1]/ul/li[3]/a').click()\n",
    "        time.sleep(.1)\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"corpTabel\"]/tbody/tr/td[1]/span/a').click()\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # 기업명\n",
    "        corp_name = i\n",
    "        # 주소\n",
    "        address = driver.find_element(By.XPATH, '//*[@id=\"corpDetailTabel\"]/tbody/tr[9]/td').text\n",
    "        # 업종명\n",
    "        sector = driver.find_element(By.XPATH, '//*[@id=\"corpDetailTabel\"]/tbody/tr[14]/td').text\n",
    "        # 설립일\n",
    "        corp_year = driver.find_element(By.XPATH, '//*[@id=\"corpDetailTabel\"]/tbody/tr[15]/td').text\n",
    "\n",
    "        ral_extra_temp = pd.DataFrame([corp_name,address,sector,corp_year], index=['기업명','주소','업종분류','설립연도']).T\n",
    "        ral_extra_res = pd.concat([ral_extra_res, ral_extra_temp])\n",
    "\n",
    "        # 키워드 지우기\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').clear()\n",
    "        time.sleep(.1)\n",
    "        \n",
    "    except:  # 검색결과가 없는 경우\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"textCrpNm\"]').clear()  # 키워드 지우기\n",
    "\n",
    "driver.quit()  # 크롤링 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 폴더에 csv파일로 저장\n",
    "ral_extra_res.to_csv('./랠릿_다트_추가.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 캐치 크롤링\n",
    "- 크롤링할 컬럼: 기업명, 기업형태, 매출액, 사원수, 업종분류, 설립연도\n",
    "- 절차\n",
    "1. url로 기업명 입력\n",
    "2. 기업정보 사이트 접속\n",
    "3. 내용 크롤링\n",
    "4. concat\n",
    "5. 다음 url 입력\n",
    "\n",
    "위 절차를 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프로그래머스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 프레임 생성\n",
    "pro_extra2_res = pd.DataFrame(columns=['기업명','기업형태','매출액','사원수','업종분류','설립연도'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 프로그램\n",
    "for name in pro_corp_name:  # 기업명 하나씩 불러오기\n",
    "    try:\n",
    "        url = f'https://www.catch.co.kr/Search/SearchDetail?Menu=2&Keyword={name}'\n",
    "\n",
    "        driver= webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"leftTop\"]/ul/li/div[2]/p[1]/a').click()  # 기업정보 클릭\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        # 기업명\n",
    "        corp_name = name\n",
    "        # 기업형태\n",
    "        corp_type = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[2]/td[1]').text\n",
    "        # 매출액\n",
    "        sales_money = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[3]/td[1]').text\n",
    "        # 사원수\n",
    "        employee = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[3]/td[2]').text\n",
    "        # 업종분류\n",
    "        sector = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[4]/td[1]').text\n",
    "        # 설립연도\n",
    "        corp_year = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[1]/td[2]').text\n",
    "\n",
    "        pro_extra2_temp = pd.DataFrame([corp_name,corp_type,sales_money,employee,sector,corp_year], index=['기업명','기업형태','매출액','사원수','업종분류','설립연도']).T\n",
    "        pro_extra2_res = pd.concat([pro_extra2_res,pro_extra2_temp])\n",
    "\n",
    "        time.sleep(0.2)\n",
    "    except:  # 기업정보가 없어서 클릭되지 않는 경우\n",
    "        pass\n",
    "    \n",
    "    driver.quit()  # 크롤링 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 폴더에 csv파일로 저장\n",
    "pro_extra2_res.to_csv('./프로그래머스_캐치_추가.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랠릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 프레임 생성\n",
    "ral_extra2_res = pd.DataFrame(columns=['기업명','기업형태','매출액','사원수','업종분류','설립연도'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 프로그램\n",
    "for name in ral_corp_name:  # 기업명 하나씩 불러오기\n",
    "    try:\n",
    "        url = f'https://www.catch.co.kr/Search/SearchDetail?Menu=2&Keyword={name}'\n",
    "\n",
    "        driver= webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"leftTop\"]/ul/li/div[2]/p[1]/a').click()  # 기업정보 클릭\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        # 기업명\n",
    "        corp_name = name\n",
    "        # 기업형태\n",
    "        corp_type = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[2]/td[1]').text\n",
    "        # 매출액\n",
    "        sales_money = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[3]/td[1]').text\n",
    "        # 사원수\n",
    "        employee = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[3]/td[2]').text\n",
    "        # 업종분류\n",
    "        sector = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[4]/td[1]').text\n",
    "        # 설립연도\n",
    "        corp_year = driver.find_element(By.XPATH, '//*[@id=\"Contents\"]/div[2]/div[1]/table/tbody/tr[1]/td[2]').text\n",
    "\n",
    "        ral_extra2_temp = pd.DataFrame([corp_name,corp_type,sales_money,employee,sector,corp_year], index=['기업명','기업형태','매출액','사원수','업종분류','설립연도']).T\n",
    "        ral_extra2_res = pd.concat([ral_extra2_res,ral_extra2_temp])\n",
    "\n",
    "        time.sleep(0.2)\n",
    "    except:  # 기업정보가 없어서 클릭되지 않는 경우\n",
    "        pass\n",
    "    \n",
    "    driver.quit()  # 크롤링 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 폴더에 csv파일로 저장\n",
    "ral_extra2_res.to_csv('./랠릿_캐치_추가.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
