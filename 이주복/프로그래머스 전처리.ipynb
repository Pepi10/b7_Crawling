{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "※ 주의사항: 전처리 관련 모든 파일은 현재 폴더에 저장해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_df = pd.read_csv('./크롤링 프로그램/programmers.csv', index_col=0)  # 기존\n",
    "dart_df = pd.read_csv('./크롤링 프로그램/dart_result.csv', index_col=0)  # 다트\n",
    "want_df = pd.read_csv('./크롤링 프로그램/wantedinsight_result.csv', index_col= 0)  # 원티드 인사이트\n",
    "incru_df = pd.read_csv('./크롤링 프로그램/incruit_result.csv')  # 인크루트\n",
    "cat_df = pd.read_csv('./크롤링 프로그램/catch_result.csv', index_col=0)  # 캐치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 프로그래머스 전처리\n",
    "- 주소\n",
    "- 사원수\n",
    "- 직급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소 전처리\n",
    "address_list = []\n",
    "\n",
    "for ad in pro_df['주소']:\n",
    "    # 우편번호 패턴을 찾아서 제거\n",
    "    ad = re.sub(r'^\\d{5}\\s', '', ad).strip()\n",
    "    # 글자 변경\n",
    "    if '대한민국' in ad:\n",
    "        ad = re.sub('대한민국', '', ad).strip()\n",
    "    elif '서울' in ad and '특별시' not in ad:\n",
    "        ad = re.sub('서울','서울특별시',ad).strip()\n",
    "    elif '경기' in ad and '경기도' not in ad:\n",
    "        ad = re.sub('경기','경기도',ad).strip()\n",
    "    elif '인천' in ad and '광역시' not in ad:\n",
    "        ad = re.sub('인천','인천광역시',ad).strip()\n",
    "\n",
    "    address_list.append(ad)\n",
    "\n",
    "# 구,시,도로 끝나는 단어 리스트 정렬\n",
    "add_list = [' '.join(re.findall(r'\\b(\\w+[구시도])\\b', address)) for address in address_list]\n",
    "\n",
    "pro_df['주소'] = add_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사원수 전처리\n",
    "employee_list = []\n",
    "\n",
    "# '명' 및 공백 제거\n",
    "for emp in pro_df['사원수']:\n",
    "    employee_list.append(int(re.sub('명','',emp).strip()))\n",
    "\n",
    "pro_df['사원수'] = employee_list\n",
    "pro_df['사원수'] = pro_df['사원수'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직급 전처리\n",
    "career_list = []\n",
    "\n",
    "for car in pro_df['직급']:\n",
    "    if '무관' not in car:  # 무관이 없는 경우 최소단위\n",
    "        career_list.append(car.split('~')[0].strip())\n",
    "\n",
    "    elif '신입' in car:  # 신입인 경우 0\n",
    "        career_list.append(0)\n",
    "                           \n",
    "    else:  # 무관이 있는 경우 0\n",
    "        career_list.append(0) \n",
    "\n",
    "pro_df['직급'] = career_list\n",
    "pro_df['직급'] = pro_df['직급'].astype(int)  # int타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 재설정\n",
    "pro_df.reset_index(drop=True, inplace=True)\n",
    "# 전처리된 파일 저장\n",
    "pro_df.to_csv('./pro_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 인크루트 전처리\n",
    "- 설립연도\n",
    "- 매출액\n",
    "- 사원수\n",
    "- 주소\n",
    "- 기업 홈페이지 URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설립연도\n",
    "corp_year_df = []\n",
    "\n",
    "for ss in incru_df.설립연도:\n",
    "    if ss != '-':\n",
    "        corp_year_df.append(int(''.join(re.findall(r'\\d\\d\\d\\d', ss))))\n",
    "    else:\n",
    "        corp_year_df.append(None)\n",
    "\n",
    "\n",
    "incru_df.설립연도 = corp_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매출액\n",
    "sales_data = []\n",
    "sales_df = []\n",
    "data_sales_res = []\n",
    "\n",
    "for sales in incru_df.매출액:\n",
    "    if sales != '-':\n",
    "        sales_data.append(sales.replace(',',''))\n",
    "    else:\n",
    "        sales_data.append(None)\n",
    "\n",
    "for qq in sales_data:\n",
    "    if qq != None:\n",
    "        sales_df.append(re.sub(r'\\(\\d{4}\\)', '', qq.replace(' ','')))\n",
    "    else:\n",
    "        sales_df.append(None)\n",
    "\n",
    "for q in sales_df:\n",
    "    if q != None: \n",
    "        if '조' in q:\n",
    "                data_sales_res.append(int(''.join(re.findall(r'(\\d+)조', q)))*100000000 + int(''.join(re.findall(r'(\\d+)억', q)))*10000 + int(''.join(re.findall(r'억(\\d+)', q))))\n",
    "        elif '억원' in q:\n",
    "                data_sales_res.append(int(''.join(re.findall(r'(\\d+)억원', q)))*10000)\n",
    "        elif '억' in q:\n",
    "            data_sales_res.append(int(''.join(re.findall(r'(\\d+)억', q)))*10000 + int(''.join(re.findall(r'억(\\d+)', q))))   \n",
    "        else:\n",
    "            data_sales_res.append(int(''.join(re.findall(r'(\\d+)만원', q))))\n",
    "    else:\n",
    "        data_sales_res.append(None)\n",
    "\n",
    "incru_df.매출액 = data_sales_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사원수\n",
    "emp_df = []\n",
    "\n",
    "for ww in incru_df.사원수:\n",
    "    if ww != '-':\n",
    "        emp_df.append(int(''.join(re.findall(r'\\d', ww))))\n",
    "    else:\n",
    "        emp_df.append(None)\n",
    "\n",
    "incru_df.사원수 = emp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소\n",
    "incru_df.주소.fillna(2)  # 결측치 채우기\n",
    "\n",
    "address_list = []\n",
    "add_list = []\n",
    "\n",
    "for ee in incru_df.주소:\n",
    "    try:    \n",
    "        if '경기' in ee and '경기도' not in ee:\n",
    "            ee = re.sub('경기', '경기도', ee)\n",
    "        elif '서울' in ee and '서울특별시' not in ee:\n",
    "             ee = re.sub('서울', '서울특별시', ee)\n",
    "        elif '강남구' in ee and '서울특별시' not in ee and '서울' not in ee:\n",
    "            ee = re.sub('강남구', '서울특별시 강남구', ee)\n",
    "    except:\n",
    "        ee = 0\n",
    "        \n",
    "    address_list.append(ee)\n",
    "\n",
    "for tt in address_list:\n",
    "    if tt != 0:\n",
    "        add_list.append(' '.join(re.findall(r'\\b(\\w+[구시도])\\b', tt)))\n",
    "    else:\n",
    "        add_list.append(None)\n",
    "\n",
    "incru_df.주소 = add_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업 홈페이지 URL\n",
    "incru_df['기업 홈페이지 URL'] = incru_df['기업 홈페이지 URL'].apply(lambda x: str(x)[2:])\n",
    "incru_df.loc[incru_df['기업 홈페이지 URL'] == 'n', '기업 홈페이지 URL'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 재설정\n",
    "incru_df.reset_index(drop=True, inplace=True)\n",
    "# 전처리된 파일 저장\n",
    "incru_df.to_csv('./incru_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 다트 전처리\n",
    "- 설립연도\n",
    "- 주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_df.설립연도 = dart_df.설립연도.apply(lambda x: ''.join(re.findall(r'\\d\\d\\d\\d', x)))  # 설립연도\n",
    "dart_df.주소 = dart_df.주소.apply(lambda x: ' '.join(re.findall(r'\\b(\\w+[구시도])\\b', x)))  # 주소\n",
    "dart_df.설립연도 = dart_df.설립연도.astype(int)  # 타입변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 재설정\n",
    "dart_df.reset_index(drop=True, inplace=True)\n",
    "# 전처리된 파일 저장\n",
    "dart_df.to_csv('./dart_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 원티드 인사이트 전처리\n",
    "- 업종분류\n",
    "- 설립연도\n",
    "- 매출액\n",
    "- 사원수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘못된 값 결측치로 변경\n",
    "want_df.loc[want_df.업종분류 == '-', '업종분류'] = None  # 업종분류\n",
    "want_df.loc[want_df.매출액 == '-원', '매출액'] = None  # 매출액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설립연도\n",
    "want_df.설립연도 = want_df.설립연도.apply(lambda x: int(''.join(re.findall(r'(\\d\\d\\d\\d)', x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사원수 잘못된 값 결측치로 변경\n",
    "want_df.loc[want_df.사원수 == '정보없음', '사원수'] = None\n",
    "want_df.loc[want_df.사원수 == 'nan', '사원수'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매출액\n",
    "want_df_sales = []\n",
    "want_df_sales_res = []\n",
    "\n",
    "for q in want_df['매출액']:\n",
    "    if q != None:\n",
    "        want_df_sales.append(q.replace(',',''))\n",
    "    else:\n",
    "        want_df_sales.append(None)\n",
    "\n",
    "try:\n",
    "    for q in want_df_sales:\n",
    "        if q != None: \n",
    "            if '조' in q:\n",
    "                    want_df_sales_res.append(int(''.join(re.findall(r'(\\d+)조', q)))*100000000 + int(''.join(re.findall(r'(\\d+)억', q)))*10000 + int(''.join(re.findall(r'억(\\d+)', q))))\n",
    "            elif '억원' in q:\n",
    "                 want_df_sales_res.append(int(''.join(re.findall(r'(\\d+)억원', q)))*10000)\n",
    "            elif '억' in q:\n",
    "               want_df_sales_res.append(int(''.join(re.findall(r'(\\d+)억', q)))*10000 + int(''.join(re.findall(r'억(\\d+)', q))))   \n",
    "            else:\n",
    "                want_df_sales_res.append(int(''.join(re.findall(r'(\\d+)만원', q))))\n",
    "        else:\n",
    "            want_df_sales_res.append(None)\n",
    "except:\n",
    "     print(q)\n",
    "\n",
    "want_df['매출액'] = want_df_sales_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사원수\n",
    "want_df_emp = []\n",
    "\n",
    "for f in want_df['사원수']:\n",
    "    if pd.notna(f):\n",
    "        want_df_emp.append(int(''.join(re.findall(r'\\d', f))))\n",
    "    else:\n",
    "        want_df_emp.append(None)\n",
    "        \n",
    "want_df.사원수 = want_df_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 재설정\n",
    "want_df.reset_index(drop=True, inplace=True)\n",
    "# 전처리된 파일 저장\n",
    "want_df.to_csv('./want_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 캐치 전처리\n",
    "- 매출액\n",
    "- 사원수\n",
    "- 설립연도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 변경: '설립일'을 '설립연도'로 변경\n",
    "cat_df.rename(columns={'설립일': '설립연도', '상세업종': '업종분류', '기업규모': '기업형태'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매출액 전처리\n",
    "m_list = []  \n",
    "m_list2 = []  \n",
    "m_list3 = []\n",
    "# '조'와 '억'만 남기기\n",
    "for m in cat_df['매출액']:\n",
    "    if m == None:  # 결측치인 경우 str타입으로 변경\n",
    "        m_list.append(str(m))\n",
    "    elif '재무제표' in str(m):\n",
    "        m_list.append(re.sub('\\n', '', m.split(':')[-1].strip()))\n",
    "    else:\n",
    "        m_list.append(re.sub('\\n', '', str(m)).split()[0])\n",
    "# 억에서 , 제외하기\n",
    "for m2 in m_list:\n",
    "    m_list2.append(re.sub(',', '', m2))\n",
    "\n",
    "# 조, 억, 만원을 만의단위로 변경하기\n",
    "for m3 in m_list2:\n",
    "    if m3 == '-' or m3 == 'nan':  # 결측치 처리\n",
    "        m_list3.append(None)\n",
    "    else:\n",
    "        조_matches = re.findall(r'(\\d+)조', m3)\n",
    "        조 = int(조_matches[0]) * 10**8 if 조_matches else 0\n",
    "\n",
    "        억_matches = re.findall(r'(\\d+)억', m3)\n",
    "        억 = int(억_matches[0]) * 10**4 if 억_matches else 0\n",
    "\n",
    "        만원_matches = re.findall(r'(\\d+)만원', m3)\n",
    "        만원 = int(만원_matches[0]) if 만원_matches else 0\n",
    "\n",
    "        m_list3.append(조 + 억 + 만원)\n",
    "        \n",
    "cat_df['매출액'] = m_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사원수\n",
    "peo_list =[]\n",
    "\n",
    "for p in cat_df['사원수']:\n",
    "    try:\n",
    "        if '-명' in p:\n",
    "            peo_list.append(None)\n",
    "        elif '명' in p:\n",
    "            peo_list.append(int(re.findall(r'\\d+', re.sub(',', '', p))[0]))\n",
    "    except:\n",
    "        peo_list.append(None)\n",
    "\n",
    "cat_df['사원수'] = peo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설립연도\n",
    "year_list = []\n",
    "\n",
    "for y in cat_df['설립연도']:\n",
    "    try:\n",
    "        year_list.append(int(re.findall(r'\\d+', y)[0]))\n",
    "    except:\n",
    "        year_list.append(None)\n",
    "        \n",
    "cat_df['설립연도'] = year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 재설정\n",
    "cat_df.reset_index(drop=True, inplace=True)\n",
    "# 전처리된 파일 저장\n",
    "cat_df.to_csv('./cat_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 데이터에 전처리된 파일들 머지하기\n",
    "- 머지 순서는 위에서 정리한 1번부터 5번까지 진행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qhr22\\AppData\\Local\\Temp\\ipykernel_44148\\795847017.py:11: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  df_merge1[orig_col] = df_merge1[orig_col].combine_first(df_merge1[col])\n"
     ]
    }
   ],
   "source": [
    "# 프로그래머스에 인크루트 머지\n",
    "df_merge1 = pd.merge(pro_df, incru_df, on='기업명', how='left', suffixes=('', '_incru'))\n",
    "\n",
    "# 합친 데이터프레임에서 인크루트에서 온 컬럼만 선택하기\n",
    "cols_to_update = [col for col in df_merge1.columns if '_incru' in col]\n",
    "\n",
    "# 원래 컬럼의 결측치를 인크루트에서 가져온 값으로 채우기\n",
    "for col in cols_to_update:\n",
    "    orig_col = col.replace('_incru', '')  # 원래 컬럼 이름\n",
    "    # 원래 컬럼의 결측치를 채움\n",
    "    df_merge1[orig_col] = df_merge1[orig_col].combine_first(df_merge1[col])\n",
    "\n",
    "# 추가된 컬럼 제거\n",
    "df_merge1.drop(columns=cols_to_update, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다트 머지\n",
    "df_merge2 = pd.merge(df_merge1, dart_df, on='기업명', how='left', suffixes=('', '_dart'))\n",
    "\n",
    "# 합친 데이터프레임에서 다트에서 온 컬럼만 선택하기\n",
    "cols_to_update = [col for col in df_merge2.columns if '_dart' in col]\n",
    "\n",
    "# 원래 컬럼의 결측치를 다트에서 가져온 값으로 채우기\n",
    "for col in cols_to_update:\n",
    "    orig_col = col.replace('_dart', '')  # 원래 컬럼 이름\n",
    "    # 원래 컬럼의 결측치를 채움\n",
    "    df_merge2[orig_col] = df_merge2[orig_col].combine_first(df_merge2[col])\n",
    "\n",
    "# 추가된 컬럼 제거\n",
    "df_merge2.drop(columns=cols_to_update, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qhr22\\AppData\\Local\\Temp\\ipykernel_44148\\4098886825.py:11: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  df_merge3[orig_col] = df_merge3[orig_col].combine_first(df_merge3[col])\n"
     ]
    }
   ],
   "source": [
    "# 원티드 인사이트 머지\n",
    "df_merge3 = pd.merge(df_merge2, want_df, on='기업명', how='left', suffixes=('', '_wanted'))\n",
    "\n",
    "# 합친 데이터프레임에서 원티드 인사이트에서 온 컬럼만 선택하기\n",
    "cols_to_update = [col for col in df_merge3.columns if '_wanted' in col]\n",
    "\n",
    "# 원래 컬럼의 결측치를 원티드 인사이트에서 가져온 값으로 채우기\n",
    "for col in cols_to_update:\n",
    "    orig_col = col.replace('_wanted', '')  # 원래 컬럼 이름\n",
    "    # 원래 컬럼의 결측치를 채움\n",
    "    df_merge3[orig_col] = df_merge3[orig_col].combine_first(df_merge3[col])\n",
    "\n",
    "# 추가된 컬럼 제거\n",
    "df_merge3.drop(columns=cols_to_update, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qhr22\\AppData\\Local\\Temp\\ipykernel_44148\\2481769147.py:11: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  df_merge4[orig_col] = df_merge4[orig_col].combine_first(df_merge4[col])\n"
     ]
    }
   ],
   "source": [
    "# 캐치 머지\n",
    "df_merge4 = pd.merge(df_merge3, cat_df, on='기업명', how='left', suffixes=('', '_catch'))\n",
    "\n",
    "# 합친 데이터프레임에서 캐치에서 온 컬럼만 선택하기\n",
    "cols_to_update = [col for col in df_merge4.columns if '_catch' in col]\n",
    "\n",
    "# 원래 컬럼의 결측치를 캐치에서 가져온 값으로 채우기\n",
    "for col in cols_to_update:\n",
    "    orig_col = col.replace('_catch', '')  # 원래 컬럼 이름\n",
    "    # 원래 컬럼의 결측치를 채움\n",
    "    df_merge4[orig_col] = df_merge4[orig_col].combine_first(df_merge4[col])\n",
    "\n",
    "# 추가된 컬럼 제거\n",
    "df_merge4.drop(columns=cols_to_update, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 값 제거 및 index 재설정\n",
    "df_merge4 = df_merge4.drop_duplicates().reset_index(drop=True)\n",
    "# 컬럼 순서 지정\n",
    "df_merge4 = df_merge4[['기업명', '업종분류', '사원수', '설립연도', '기업형태', '매출액', '주소', '직무', '이용하는 기술스택',\n",
    "            '자격요건', '직급', '우대사항', '해당 페이지 URL', '기업 홈페이지 URL']]\n",
    "\n",
    "# 최종 파일 저장\n",
    "df_merge4.to_csv('./programmers_end.csv')\n",
    "df_merge4.to_excel('./programmers_end.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
