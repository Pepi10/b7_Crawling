{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wanted Crawling Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수코드\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "# 함수 생성\n",
    "def wanted_crawling_program(start_post, end_post):\n",
    "    # 크롬옵션 설정\n",
    "    chrome_options = Options()\n",
    "    # 꺼짐 방지 (gqu가속 x)\n",
    "    chrome_options.add_argument('--disable-gpu') \n",
    "    # 창 크기에 따라 XPATH가 달라져 크기 고정\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    # 알림표시 제거\n",
    "    chrome_options.add_argument(\"--disable-notifications\")\n",
    "    # 옵션 적용\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    \n",
    "    url = \"https://www.wanted.co.kr/wdlist/518?country=kr&job_sort=job.recommend_order&years=-1&locations=all\"\n",
    "    # chrome url 넣어서 실행\n",
    "    driver.get(url)\n",
    "\n",
    "    # 최종 Data가 모일 곳\n",
    "    wanted_res = pd.DataFrame(\n",
    "        columns = ['기업명', '주소', '직무', '자격요건', '직급', '이용하는기술스택/우대사항', '해당 페이지 URL']\n",
    "        )\n",
    "\n",
    "    # 직무 선택 클릭\n",
    "    search_job = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located(\n",
    "        (\n",
    "            By.XPATH, '//*[@id=\"__next\"]/div[3]/article/div/div[2]/button'\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "    search_job.click()\n",
    "    \n",
    "\n",
    "\n",
    "    # 이 함수는 공고를 4회 클릭시 로그인창이 발생하는 사이트의 특성 때문에\n",
    "    # 89 번째 줄의 try에서 3개의 공고를 클릭하여 크롤링한 후 \n",
    "    # finally에서 driver를 종료시킨 다음 드라이브를 켜 반복을 이어갑니다.\n",
    "    # 직무선택 변수 button의 for반복문은 이 곳에 넣을 경우 계속 초기화 되기에 \n",
    "    # '함수의 실행코드' 에 포함시켰습니다.\n",
    "    driver.find_element(\n",
    "        By.XPATH, f'//*[@id=\"__next\"]/div[3]/article/div/div[2]/section/div[1]/div/button[{button}]'\n",
    "        ).click()\n",
    "    driver.find_element(\n",
    "        By.XPATH, '//*[@id=\"__next\"]/div[3]/article/div/div[2]/section/div[2]/button/span[2]'\n",
    "        ).click()\n",
    "    \n",
    "    \n",
    "    # aws 검색하기\n",
    "    search = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located(\n",
    "            (\n",
    "                By.XPATH, '//*[@id=\"__next\"]/div[3]/div[1]/div[1]/div/div/div[2]/button'\n",
    "                )\n",
    "                )\n",
    "                )\n",
    "    search.click()\n",
    "    # aws 입력        \n",
    "    time.sleep(0.5)\n",
    "    driver.find_element(\n",
    "        By.XPATH, '//*[@id=\"__next\"]/div[3]/div[1]/div/div/div/div[2]/section/div/div[1]/input'\n",
    "        ).send_keys('aws')\n",
    "    # 엔터        \n",
    "    time.sleep(0.5)\n",
    "    driver.find_element(\n",
    "        By.XPATH, '//*[@id=\"__next\"]/div[3]/div[1]/div/div/div/div[2]/section/div/div[1]/input'\n",
    "        ).send_keys(Keys.ENTER)\n",
    "    # 확인       \n",
    "    time.sleep(0.7)\n",
    "    driver.find_element(\n",
    "        By.XPATH, '//*[@id=\"__next\"]/div[3]/div[1]/div/div/div/div[2]/section/footer/div/button[2]/span[2]'\n",
    "        ).click()\n",
    "            \n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "    start_time_scroll = time.time()\n",
    "    \n",
    "    # 크롤링 코드블럭\n",
    "    try:\n",
    "        for post_job in range(start_post, end_post):\n",
    "            if time.time() - start_time_scroll > 60:\n",
    "                break \n",
    "            #스크롤하며 공고 찾기\n",
    "            while True:\n",
    "                try:\n",
    "                    # 공고 찾기\n",
    "                    post = driver.find_element(\n",
    "                         By.XPATH, f'//*[@id=\"__next\"]/div[3]/div[2]/ul/li[{post_job}]/div/a/div[1]'\n",
    "                         )\n",
    "                    # 있으면 클릭하고 break\n",
    "                    time.sleep(0.1)\n",
    "                    try:\n",
    "                        if post.is_displayed():\n",
    "                            post.click()\n",
    "                            break\n",
    "                    except ElementClickInterceptedException:\n",
    "                        driver.execute_script(\"window.scrollBy(0, 100);\")\n",
    "                        if post.is_displayed():\n",
    "                            post.click()\n",
    "                            break\n",
    "                except ElementClickInterceptedException:\n",
    "                    driver.execute_script(\"window.scrollBy(0, 100);\")\n",
    "                    if post.is_displayed():\n",
    "                        post.click()\n",
    "                        break\n",
    "                          \n",
    "\n",
    "                # 없으면 오류제거하고 while True 반복 진행\n",
    "                except NoSuchElementException:\n",
    "                    pass\n",
    "\n",
    "\n",
    "                # 스크롤 시작점=0, ?픽셀씩 내리기\n",
    "                driver.execute_script(\"window.scrollBy(0, 430);\")\n",
    "                time.sleep(0.6)\n",
    "\n",
    "                if time.time() - start_time_scroll > 60:\n",
    "                    break  \n",
    "            # while 코드 끝  \n",
    "            # while 코드에서 클릭한 공고의 data crawling 코드\n",
    "            try:\n",
    "                # 공고 클릭 후 Data Crawling\n",
    "                corp = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located(\n",
    "                        (\n",
    "                        By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/a'\n",
    "                        )\n",
    "                        )\n",
    "                        ).text\n",
    "                time.sleep(0.2)\n",
    "                #더보기 클릭\n",
    "                driver.find_element(\n",
    "                    By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/button'\n",
    "                    ).click()\n",
    "                time.sleep(0.2)\n",
    "                tec = driver.find_element(\n",
    "                    By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[3]/p/span'\n",
    "                    ).text.replace('\\n',', ')\n",
    "                time.sleep(0.2)\n",
    "                car = driver.find_element(\n",
    "                    By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/span[4]'\n",
    "                    ).text\n",
    "                time.sleep(0.2)\n",
    "                post_url = [q.get_attribute('href') for q in driver.find_elements(By.TAG_NAME, 'link')][0]\n",
    "                time.sleep(0.2)\n",
    "                main = re.sub(\n",
    "                    '\\s', '', driver.find_element(\n",
    "                        By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[2]/p/span'\n",
    "                        ).text\n",
    "                        ).replace('-', ', ')[1:]\n",
    "                time.sleep(0.2)\n",
    "                try:\n",
    "                    address = driver.find_element(\n",
    "                        By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[4]/div/div/span'\n",
    "                        ).text\n",
    "                except:\n",
    "                    address = driver.find_element(\n",
    "                        By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[5]/div/div/span'\n",
    "                        ).text\n",
    "                \n",
    "            except:\n",
    "                None\n",
    "            \n",
    "            # Data 인덱스 아래부터 concat\n",
    "            wanted_temp = pd.DataFrame(\n",
    "                [corp, address, button, main, car, tec, post_url],\n",
    "                index = ['기업명', '주소', '직무', '자격요건', '직급', '이용하는기술스택/우대사항', '해당 페이지 URL']\n",
    "                ).T\n",
    "            wanted_res = pd.concat(\n",
    "                [wanted_res, wanted_temp]\n",
    "                )\n",
    "            \n",
    "            time.sleep(0.3)\n",
    "            # 뒤로가기\n",
    "            driver.back()\n",
    "            time.sleep(0.3)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return wanted_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# 실행 코드\n",
    "\n",
    "final_wan_res = pd.DataFrame(columns=['기업명', '주소', '직무', '자격요건', '직급', '이용하는기술스택/우대사항', '해당 페이지 URL'])\n",
    "for button in range(36, 39):\n",
    "    # for start_post in range(처음 post, 최대 post, 로그인 페이지방지: 3 추천)\n",
    "    for start_post in range(1, 300, 3):\n",
    "        try:\n",
    "            # end_post = start_post + 로그인 페이지 방지 숫자\n",
    "            end_post = start_post + 3\n",
    "            final_wan_res = pd.concat(\n",
    "                [final_wan_res, wanted_crawling_program(start_post, end_post)]\n",
    "                )\n",
    "        \n",
    "        except UnboundLocalError:\n",
    "            break \n",
    "\n",
    "\n",
    "# 직무 숫자를 직무로 변경하는 코드\n",
    "\n",
    "# 크롬옵션 설정\n",
    "chrome_options = Options()\n",
    "# 꺼짐 방지 (gqu가속 x)\n",
    "chrome_options.add_argument('--disable-gpu') \n",
    "# 창 크기에 따라 XPATH가 달라져 크기 고정\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "# 알림표시 제거\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "# 옵션 적용\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "url = \"https://www.wanted.co.kr/wdlist/518?country=kr&job_sort=job.recommend_order&years=-1&locations=all\"\n",
    "# chrome url 넣어서 실행\n",
    "driver.get(url)\n",
    "\n",
    "# 직무 선택\n",
    "search_job = WebDriverWait(driver, 10).until(\n",
    "EC.presence_of_element_located(\n",
    "    (\n",
    "        By.XPATH, '//*[@id=\"__next\"]/div[3]/article/div/div[2]/button'\n",
    "        )\n",
    "        )\n",
    "        )\n",
    "search_job.click()\n",
    "\n",
    "# 직무 숫자에 맞춰 직무 list 만들기\n",
    "job_description_list = []\n",
    "for mung in range(2,39):\n",
    "    job_description_list.append(driver.find_element(By.XPATH, f'//*[@id=\"__next\"]/div[3]/article/div/div[2]/section/div[1]/div/button[{mung}]').text)\n",
    "\n",
    "# 직무 list를 직무에 적용\n",
    "for job_description in range(2,39):\n",
    "    final_wan_res.loc[final_wan_res.직무 == job_description, '직무'] = job_description_list[job_description - 2]\n",
    "    time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
