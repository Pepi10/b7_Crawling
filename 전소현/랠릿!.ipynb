{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987f6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4767229e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m\n\u001b[0;32m     39\u001b[0m qualification \u001b[38;5;241m=\u001b[39m sub_soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp.css-19hzmb1\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# 자격요건\u001b[39;00m\n\u001b[0;32m     41\u001b[0m temp_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기업명\u001b[39m\u001b[38;5;124m'\u001b[39m: company,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m주소\u001b[39m\u001b[38;5;124m'\u001b[39m: address,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m자격요건\u001b[39m\u001b[38;5;124m'\u001b[39m: qualification\n\u001b[0;32m     49\u001b[0m }\n\u001b[1;32m---> 51\u001b[0m rallit_res \u001b[38;5;241m=\u001b[39m rallit_res\u001b[38;5;241m.\u001b[39mappend(temp_dict, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# 뒤로 가기\u001b[39;00m\n\u001b[0;32m     54\u001b[0m driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.history.go(-1)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "keyword = \"AWS\"\n",
    "page = 1\n",
    "main_url = \"https://www.rallit.com\"\n",
    "rallit_res = pd.DataFrame(columns=['기업명', '주소', '직무', '직급', '우대사항/기술스택', '해당 페이지URL', '자격요건'])\n",
    "\n",
    "# 웹 드라이버 초기화\n",
    "driver = webdriver.Chrome()  # 혹은 다른 브라우저에 맞게 변경\n",
    "\n",
    "while True:\n",
    "    url = f'https://www.rallit.com/?jobSkillKeywords={keyword}&pageNumber={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    if \"검색결과가 없어요\" in soup.text:\n",
    "        break\n",
    "\n",
    "    # 각 공고를 클릭하여 정보 수집\n",
    "    job_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[3]/ul/li/article/a/figure/img')\n",
    "    for job_element in job_elements:\n",
    "        job_element.click()\n",
    "        time.sleep(3)  # 공고 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "        sub_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        company = sub_soup.select_one('h2').text.strip()  # 기업명\n",
    "        address = sub_soup.select_one('p.css-1hdnp7d').text.strip()  # 주소\n",
    "        position = sub_soup.select_one('dd.css-1pvdrt3').text.strip()  # 직급\n",
    "        job = sub_soup.select('p.css-19hzmb1')[1].text.strip()  # 직무\n",
    "        favor = sub_soup.select('p.css-19hzmb1')[4].text.strip()  # 우대사항, 기술스택\n",
    "        employment_url = driver.current_url\n",
    "        qualification = sub_soup.select('p.css-19hzmb1')[3].text.strip()  # 자격요건\n",
    "\n",
    "        temp_dict = {\n",
    "            '기업명': company,\n",
    "            '주소': address,\n",
    "            '직무': job,\n",
    "            '직급': position,\n",
    "            '우대사항/기술스택': favor,\n",
    "            '해당 페이지URL': employment_url,\n",
    "            '자격요건': qualification\n",
    "        }\n",
    "\n",
    "        rallit_res = rallit_res.append(temp_dict, ignore_index=True)\n",
    "\n",
    "        # 뒤로 가기\n",
    "        driver.execute_script(\"window.history.go(-1)\")\n",
    "        time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# 크롤링이 끝나면 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 결과 확인\n",
    "print(rallit_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb2fba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found\n  (Session info: chrome=122.0.6261.70); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF79EEDAD22+56930]\n\t(No symbol) [0x00007FF79EE4F622]\n\t(No symbol) [0x00007FF79ED042E5]\n\t(No symbol) [0x00007FF79ED09261]\n\t(No symbol) [0x00007FF79ED0B6EB]\n\t(No symbol) [0x00007FF79ED0B7B0]\n\t(No symbol) [0x00007FF79ED4B705]\n\t(No symbol) [0x00007FF79ED3F526]\n\t(No symbol) [0x00007FF79ED6BC9A]\n\t(No symbol) [0x00007FF79ED3F09A]\n\t(No symbol) [0x00007FF79ED6BEB0]\n\t(No symbol) [0x00007FF79ED881E2]\n\t(No symbol) [0x00007FF79ED6BA43]\n\t(No symbol) [0x00007FF79ED3D438]\n\t(No symbol) [0x00007FF79ED3E4D1]\n\tGetHandleVerifier [0x00007FF79F256AAD+3709933]\n\tGetHandleVerifier [0x00007FF79F2AFFED+4075821]\n\tGetHandleVerifier [0x00007FF79F2A817F+4043455]\n\tGetHandleVerifier [0x00007FF79EF79756+706710]\n\t(No symbol) [0x00007FF79EE5B8FF]\n\t(No symbol) [0x00007FF79EE56AE4]\n\t(No symbol) [0x00007FF79EE56C3C]\n\t(No symbol) [0x00007FF79EE468F4]\n\tBaseThreadInitThunk [0x00007FFD9314257D+29]\n\tRtlUserThreadStart [0x00007FFD9400AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m job_elements \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__next\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/main/div/section[3]/ul/li/article/a/figure/img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job_element \u001b[38;5;129;01min\u001b[39;00m job_elements:\n\u001b[1;32m---> 28\u001b[0m     job_element\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     29\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# 공고 페이지가 완전히 로드될 때까지 잠시 대기\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     sub_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mCLICK_ELEMENT)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: chrome=122.0.6261.70); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF79EEDAD22+56930]\n\t(No symbol) [0x00007FF79EE4F622]\n\t(No symbol) [0x00007FF79ED042E5]\n\t(No symbol) [0x00007FF79ED09261]\n\t(No symbol) [0x00007FF79ED0B6EB]\n\t(No symbol) [0x00007FF79ED0B7B0]\n\t(No symbol) [0x00007FF79ED4B705]\n\t(No symbol) [0x00007FF79ED3F526]\n\t(No symbol) [0x00007FF79ED6BC9A]\n\t(No symbol) [0x00007FF79ED3F09A]\n\t(No symbol) [0x00007FF79ED6BEB0]\n\t(No symbol) [0x00007FF79ED881E2]\n\t(No symbol) [0x00007FF79ED6BA43]\n\t(No symbol) [0x00007FF79ED3D438]\n\t(No symbol) [0x00007FF79ED3E4D1]\n\tGetHandleVerifier [0x00007FF79F256AAD+3709933]\n\tGetHandleVerifier [0x00007FF79F2AFFED+4075821]\n\tGetHandleVerifier [0x00007FF79F2A817F+4043455]\n\tGetHandleVerifier [0x00007FF79EF79756+706710]\n\t(No symbol) [0x00007FF79EE5B8FF]\n\t(No symbol) [0x00007FF79EE56AE4]\n\t(No symbol) [0x00007FF79EE56C3C]\n\t(No symbol) [0x00007FF79EE468F4]\n\tBaseThreadInitThunk [0x00007FFD9314257D+29]\n\tRtlUserThreadStart [0x00007FFD9400AA58+40]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "keyword = \"AWS\"\n",
    "page = 1\n",
    "main_url = \"https://www.rallit.com\"\n",
    "rallit_res = pd.DataFrame()\n",
    "\n",
    "# 웹 드라이버 초기화\n",
    "driver = webdriver.Chrome()  # 혹은 다른 브라우저에 맞게 변경\n",
    "\n",
    "while True:\n",
    "    url = f'https://www.rallit.com/?jobSkillKeywords={keyword}&pageNumber={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    if \"검색결과가 없어요\" in soup.text:\n",
    "        break\n",
    "\n",
    "    # 각 공고를 클릭하여 정보 수집\n",
    "    job_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[3]/ul/li/article/a/figure/img')\n",
    "    for job_element in job_elements:\n",
    "        job_element.click()\n",
    "        time.sleep(3)  # 공고 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "        sub_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        company = sub_soup.select_one('h2').text.strip()  # 기업명\n",
    "        address = sub_soup.select_one('p.css-1hdnp7d').text.strip()  # 주소\n",
    "        position = sub_soup.select_one('dd.css-1pvdrt3').text.strip()  # 직급\n",
    "        job = sub_soup.select('p.css-19hzmb1')[1].text.strip()  # 직무\n",
    "        favor = sub_soup.select('p.css-19hzmb1')[4].text.strip()  # 우대사항, 기술스택\n",
    "        employment_url = driver.current_url\n",
    "        qualification = sub_soup.select('p.css-19hzmb1')[3].text.strip()  # 자격요건\n",
    "\n",
    "        temp_dict = {\n",
    "            '기업명': company,\n",
    "            '주소': address,\n",
    "            '직무': job,\n",
    "            '직급': position,\n",
    "            '우대사항/기술스택': favor,\n",
    "            '해당 페이지URL': employment_url,\n",
    "            '자격요건': qualification\n",
    "        }\n",
    "\n",
    "        temp_df = pd.DataFrame([temp_dict])\n",
    "        rallit_res = pd.concat([rallit_res, temp_df], ignore_index=True)\n",
    "\n",
    "        # 뒤로 가기\n",
    "        driver.execute_script(\"window.history.go(-1)\")\n",
    "        time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# 크롤링이 끝나면 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 결과 확인\n",
    "print(rallit_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeab43bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 57\u001b[0m\n\u001b[0;32m     45\u001b[0m qualification \u001b[38;5;241m=\u001b[39m sub_soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp.css-19hzmb1\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sub_soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp.css-19hzmb1\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 자격요건\u001b[39;00m\n\u001b[0;32m     47\u001b[0m temp_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기업명\u001b[39m\u001b[38;5;124m'\u001b[39m: company,\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m주소\u001b[39m\u001b[38;5;124m'\u001b[39m: address,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m자격요건\u001b[39m\u001b[38;5;124m'\u001b[39m: qualification\n\u001b[0;32m     55\u001b[0m }\n\u001b[1;32m---> 57\u001b[0m rallit_res \u001b[38;5;241m=\u001b[39m rallit_res\u001b[38;5;241m.\u001b[39mappend(temp_dict, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 뒤로 가기\u001b[39;00m\n\u001b[0;32m     60\u001b[0m driver\u001b[38;5;241m.\u001b[39mback()\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "keyword = \"AWS\"\n",
    "page = 1\n",
    "main_url = \"https://www.rallit.com\"\n",
    "rallit_res = pd.DataFrame()\n",
    "\n",
    "# 웹 드라이버 초기화\n",
    "driver = webdriver.Chrome()  # 혹은 다른 브라우저에 맞게 변경\n",
    "\n",
    "while True:\n",
    "    url = f'https://www.rallit.com/?jobSkillKeywords={keyword}&pageNumber={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    if \"검색결과가 없어요\" in soup.text:\n",
    "        break\n",
    "\n",
    "    # 각 공고를 클릭하여 정보 수집\n",
    "    job_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[3]/ul/li/article/a/figure/img')\n",
    "    for i in range(len(job_elements)):\n",
    "        job_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[3]/ul/li/article/a/figure/img')\n",
    "        job_element = job_elements[i]\n",
    "        job_element.click()\n",
    "\n",
    "        # 공고 페이지가 완전히 로드될 때까지 대기\n",
    "        WebDriverWait(driver, 10).until(EC.url_changes(driver.current_url))\n",
    "\n",
    "        sub_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        company = sub_soup.select_one('h2').text.strip() if sub_soup.select_one('h2') else \"\" # 기업명\n",
    "        address = sub_soup.select_one('p.css-1hdnp7d').text.strip() if sub_soup.select_one('p.css-1hdnp7d') else \"\"  # 주소\n",
    "        position = sub_soup.select_one('dd.css-1pvdrt3').text.strip() if sub_soup.select_one('dd.css-1pvdrt3') else \"\"  # 직급\n",
    "        job = sub_soup.select('p.css-19hzmb1')[1].text.strip() if len(sub_soup.select('p.css-19hzmb1')) > 1 else \"\"  # 직무\n",
    "        favor = sub_soup.select('p.css-19hzmb1')[4].text.strip() if len(sub_soup.select('p.css-19hzmb1')) > 4 else \"\"  # 우대사항, 기술스택\n",
    "        employment_url = driver.current_url\n",
    "        qualification = sub_soup.select('p.css-19hzmb1')[3].text.strip() if len(sub_soup.select('p.css-19hzmb1')) > 3 else \"\"  # 자격요건\n",
    "\n",
    "        temp_dict = {\n",
    "            '기업명': company,\n",
    "            '주소': address,\n",
    "            '직무': job,\n",
    "            '직급': position,\n",
    "            '우대사항/기술스택': favor,\n",
    "            '해당 페이지URL': employment_url,\n",
    "            '자격요건': qualification\n",
    "        }\n",
    "\n",
    "        rallit_res = rallit_res.append(temp_dict, ignore_index=True)\n",
    "\n",
    "        # 뒤로 가기\n",
    "        driver.back()\n",
    "        time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# 크롤링이 끝나면 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 결과 확인\n",
    "print(rallit_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f0d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            기업명                                         주소  \\\n",
      "0          오비맥주       서울 강남구 영동대로 517 ASEM 및 한국종합무역센타단지 8층   \n",
      "1    사이벨 헬스 (주)                                              \n",
      "2          와탭랩스        서울 서초구 서초대로77길 17 BLOCK77 13층 1303호   \n",
      "3     인프랩 (인프런)   경기 성남시 분당구 대왕판교로 660 유스페이스1 1A 동 4층 405호   \n",
      "4   롯데헬스케어 주식회사          서울 송파구 올림픽로 300 롯데월드타워앤드롯데월드몰 27층   \n",
      "..          ...                                        ...   \n",
      "62       (주)디랙스                                              \n",
      "63     주식회사그로잉랩                                              \n",
      "64        리본솔루션  인천 연수구 갯벌로 12 갯벌타워 별관 A동 511호(송도동, 미추홀타워)   \n",
      "65    (주)엔블리스컴즈        서울 동작구 노량진로 10 여성가족복합시설 스페이스살림 503호   \n",
      "66   (주)디에스랩글로벌              서울 영등포구 의사당대로 83 오투타워 5층 103호   \n",
      "\n",
      "                                                   직무           직급  \\\n",
      "0   오비맥주 Strategy & Technology팀에서 Sr. Data Enginee...  시니어 (9년 이상)   \n",
      "1   의료 데이터를 전송, 처리, 저장하는데 사용될 안전한 클라우드 인프라를 설계하고 개...    미들 (4~8년)   \n",
      "2            와탭랩스 개발팀에서 모니터링 서비스를 함께 만들어나갈 분을 찾고있습니다.    미들 (4~8년)   \n",
      "3                 인프런의 어드민을 비롯한 백엔드 시스템 개발 업무를 담당합니다.           인턴   \n",
      "4   \"Every Moment of your Healthy Life\" 롯데헬스케어의 서비...         경력무관   \n",
      "..                                                ...          ...   \n",
      "62  국내 운동기구 제조 1위 회사로서  장비와 함께 피트니스 AI 솔루션을 개발/공급하...         경력무관   \n",
      "63  펀더멘탈 데이터 기반의 투자 플랫폼, 버틀러를 함께 키워가실 백엔드 시니어 엔지니어...  시니어 (9년 이상)   \n",
      "64  Re:born solution(리본솔루션)의 첫 걸음에 동행하실 분, 함께 성장해 ...         경력무관   \n",
      "65                        위싱노트의 서비스를 설계하고 개발하며 운영합니다.    미들 (4~8년)   \n",
      "66  빠르게 성장중인 스타트업 디에스랩글로벌에 초기 크루로 합류하여 시리즈B, C, 그 ...    미들 (4~8년)   \n",
      "\n",
      "                                            우대사항/기술스택  \\\n",
      "0   [Tech]\\n- Experience in Data Science related p...   \n",
      "1   - DevOps 및 CI/CD, 프레임워크에 대한 숙련도가 있으신 분\\n- 하나 이...   \n",
      "2   • MSA 서비스 구축 및 운영 경험\\n• 오픈소스 모니터링 구축 경험\\n• ISM...   \n",
      "3   - TypeScript, Java, Kotlin 등 강타입 (Strongly Typ...   \n",
      "4   • JavaScript, TypeScript, Golang, Python 경험자\\n...   \n",
      "..                                                ...   \n",
      "62  우대사항\\n\\nㆍ전공 : 컴퓨터공학/AI 관련, 수학, 통계학\\n\\nㆍ솔루션 개발경...   \n",
      "63  - 다양한 환경에서 개발하신 경험이 있으신 분\\n- 서비스 인프라 설계 및 관리를 ...   \n",
      "64  • AWS 유경험자\\n• 배포 프로세스 환경 구축 및 사용 유경험자\\n• RDBMS...   \n",
      "65  - 컴퓨터공학 및 공학 관련 계열을 전공하신 분\\n- 다양한 백엔드 개발 경력을 보...   \n",
      "66  • FastAPI, Django 등 웹 프레임워크 사용 경험\\n• AWS, GCP,...   \n",
      "\n",
      "                                            해당 페이지URL  \\\n",
      "0   https://www.rallit.com/positions/1791/data-sr-...   \n",
      "1   https://www.rallit.com/positions/808/sibel-hea...   \n",
      "2   https://www.rallit.com/positions/1305/%EB%8D%B...   \n",
      "3   https://www.rallit.com/positions/2246/%EC%9D%B...   \n",
      "4   https://www.rallit.com/positions/1639/%EC%84%9...   \n",
      "..                                                ...   \n",
      "62  https://www.rallit.com/positions/1776/aws-%EC%...   \n",
      "63  https://www.rallit.com/positions/1368/%EB%B0%B...   \n",
      "64  https://www.rallit.com/positions/2272/%EB%B0%B...   \n",
      "65  https://www.rallit.com/positions/305/%EB%B0%B1...   \n",
      "66  https://www.rallit.com/positions/217/%EB%B0%B1...   \n",
      "\n",
      "                                                 자격요건  \n",
      "0   [Tech]\\n- Proficiency in programming languages...  \n",
      "1   - 컴퓨터 전공 관련학과 학사 이상\\n- 영어 회화 및 문서작업 가능자 (Spoke...  \n",
      "2   필수 자격요건 (경력: 7~12년)\\n• Shell, Python 등 하나 이상 스...  \n",
      "3   아래 개발팀의 미션과 가치에 동의하시는 분이어야 합니다.\\nhttps://tech....  \n",
      "4   • 1년 이상의 서비스 개발 및 운영 경험자\\n• 본인이 사용한 기술과 환경에 대한...  \n",
      "..                                                ...  \n",
      "62  스킬\\n\\nㆍAndroid, iOS, JAVA, JSP, MySQL, Spring ...  \n",
      "63  - 웹서비스 개발을 7년이상 경험하신 분\\n- AWS 등의 클라우드 기반 서비스를 ...  \n",
      "64                           • 백엔드 개발 및 유지보수 경력 1년 이상  \n",
      "65  - 필요한 업무 기술의 경험과 이해도가 높으신 분\\n- 웹 서비스에 대한 이해와 책...  \n",
      "66  • 백엔드 개발 경력 3년 이상\\n• 한 가지 이상의 언어를 능숙하게 다루실 수 있...  \n",
      "\n",
      "[67 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "keyword = \"AWS\"\n",
    "page = 1\n",
    "main_url = \"https://www.rallit.com\"\n",
    "rallit_res = pd.DataFrame()\n",
    "\n",
    "# 웹 드라이버 초기화\n",
    "driver = webdriver.Chrome()  # 혹은 다른 브라우저에 맞게 변경\n",
    "\n",
    "while True:\n",
    "    url = f'https://www.rallit.com/?jobSkillKeywords={keyword}&pageNumber={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    if \"검색결과가 없어요\" in soup.text:\n",
    "        break\n",
    "\n",
    "    # 각 공고를 클릭하여 정보 수집\n",
    "    job_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[3]/ul/li/article/a/figure/img')\n",
    "    for i in range(len(job_elements)):\n",
    "        job_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/section[3]/ul/li/article/a/figure/img')\n",
    "        job_element = job_elements[i]\n",
    "        job_element.click()\n",
    "\n",
    "        # 공고 페이지가 완전히 로드될 때까지 대기\n",
    "        WebDriverWait(driver, 10).until(EC.url_changes(driver.current_url))\n",
    "\n",
    "        sub_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        corp_name = sub_soup.select_one('h2').text.strip() if sub_soup.select_one('h2') else \"\" # 기업명\n",
    "        address = sub_soup.select_one('p.css-1hdnp7d').text.strip() if sub_soup.select_one('p.css-1hdnp7d') else \"\"  # 주소\n",
    "        career = sub_soup.select_one('dd.css-1pvdrt3').text.strip() if sub_soup.select_one('dd.css-1pvdrt3') else \"\"  # 직급\n",
    "        job_description = sub_soup.select('p.css-19hzmb1')[1].text.strip() if len(sub_soup.select('p.css-19hzmb1')) > 1 else \"\"  # 직무\n",
    "        favor = sub_soup.select('p.css-19hzmb1')[4].text.strip() if len(sub_soup.select('p.css-19hzmb1')) > 4 else \"\"  # 우대사항, 기술스택\n",
    "        employment_url = driver.current_url\n",
    "        job_requirements = sub_soup.select('p.css-19hzmb1')[3].text.strip() if len(sub_soup.select('p.css-19hzmb1')) > 3 else \"\"  # 자격요건\n",
    "\n",
    "        temp_dict = {\n",
    "            '기업명': corp_name,\n",
    "            '주소': address,\n",
    "            '직무': job_description,\n",
    "            '직급': career,\n",
    "            '우대사항/기술스택': favor,\n",
    "            '해당 페이지URL': employment_url,\n",
    "            '자격요건': job_requirements\n",
    "        }\n",
    "\n",
    "        temp_df = pd.DataFrame([temp_dict])\n",
    "        rallit_res = pd.concat([rallit_res, temp_df], ignore_index=True)\n",
    "\n",
    "        # 뒤로 가기\n",
    "        driver.back()\n",
    "        time.sleep(3)  # 페이지가 완전히 로드될 때까지 잠시 대기\n",
    "\n",
    "    page += 1\n",
    "\n",
    "# 크롤링이 끝나면 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 결과 확인\n",
    "print(rallit_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0feef9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 CSV 파일로 저장\n",
    "rallit_res.to_csv('rallit_1.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cccd9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
